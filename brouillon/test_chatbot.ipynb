{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.chatbot import compile_chatbot_graph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "\n",
    "graph_builder = compile_chatbot_graph()\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "config = {\"configurable\": {\"thread_id\":\"first time\"}}\n",
    "\n",
    "state = graph.get_state(config)\n",
    "print(state)\n",
    "\n",
    "\n",
    "def get_answer_from_chat(thread_id: str, message: str):\n",
    "    # config = {\"configurable\": {\"thread_id\": from_number + \"_\" + to_number_str}}\n",
    "    \n",
    "    events = graph.stream(\n",
    "        {\"messages\": [(\"user\", message)]}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    return event[\"messages\"][-1].content\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello !\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What was my first message ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your first message was \"Hello !\"\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "And my name ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I don't have access to personal data about users unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. If you tell me your name, I can remember it for the duration of our chat.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Henri\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Henri! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Say my name\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Of course! Your name is Henri. How can I help you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It looks like your message might have been cut off. How can I assist you, Henri?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It seems like your message didn't come through. If you have any questions or need assistance, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\":\"other test\"}}\n",
    "memory = MemorySaver()\n",
    "graph_builder = compile_chatbot_graph()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input()\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    get_answer_from_chat(\"thread_id\", user_input)\n",
    "    # events = graph.stream(\n",
    "    #     {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    "    # )\n",
    "\n",
    "    # for event in events:\n",
    "    #     event[\"messages\"][-1].pretty_print()\n",
    "    time.sleep(0.1)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
